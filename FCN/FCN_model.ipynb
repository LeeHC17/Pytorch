{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cee780c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from torchsummary import summary as summary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3c3dcaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN_8s(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FCN_8s, self).__init__()\n",
    "        #conv1\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size = (3,3), stride = (1,1), padding = 1)\n",
    "        self.relu1_1 = nn.ReLU(inplace=True)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size = (3,3), stride = (1,1), padding = 1)\n",
    "        self.relu1_2 = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = (2,2), stride = (2,2), padding = 0)\n",
    "        #conv2\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=(3,3), stride = (1,1), padding = 1)\n",
    "        self.relu2_1 = nn.ReLU(inplace=True)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=(3,3), stride = (1,1), padding = 1)\n",
    "        self.relu2_2 = nn.ReLU(inplace=True)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = (2,2), stride = (2,2), padding = 0)\n",
    "        #conv3\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=(3,3), stride = (1,1), padding = 1)\n",
    "        self.relu3_1 = nn.ReLU(inplace=True)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=(3,3), stride = (1,1), padding = 1)\n",
    "        self.relu3_2 = nn.ReLU(inplace=True)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=(3,3), stride = (1,1), padding = 1)\n",
    "        self.relu3_3 = nn.ReLU(inplace=True)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size = (2,2), stride = (2,2), padding = 0)\n",
    "        #conv4\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=(3,3), stride = (1,1), padding = 1)\n",
    "        self.relu4_1 = nn.ReLU(inplace=True)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=(3,3), stride = (1,1), padding = 1)\n",
    "        self.relu4_2 = nn.ReLU(inplace=True)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=(3,3), stride = (1,1), padding = 1)\n",
    "        self.relu4_3 = nn.ReLU(inplace=True)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=(2,2), stride = (2,2), padding = 0)\n",
    "        #conv5\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=(3,3), stride = (1,1), padding = 1)\n",
    "        self.relu5_1 = nn.ReLU(inplace=True)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=(3,3), stride = (1,1), padding = 1)\n",
    "        self.relu5_2 = nn.ReLU(inplace=True)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=(3,3), stride = (1,1), padding = 1)\n",
    "        self.relu5_3 = nn.ReLU(inplace=True)\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=(2,2), stride = (2,2), padding = 0)\n",
    "        #fully conv\n",
    "        self.conv6 = nn.Conv2d(512, 4096, kernel_size=(1,1), stride = (1,1), padding = 0)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        self.drop6 = nn.Dropout2d()\n",
    "        self.conv7 = nn.Conv2d(4096, 4096, kernel_size=(1,1), stride = (1,1), padding = 0)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        self.drop7 = nn.Dropout2d()\n",
    "        self.score1 = nn.Conv2d(4096, 21, kernel_size = (1,1), stride = (1,1), padding = 0)\n",
    "        #upsampling\n",
    "        self.x2upsamp = nn.ConvTranspose2d(21, 21, kernel_size = (4,4), stride = (2,2), padding = 1)\n",
    "        self.x8upsamp = nn.ConvTranspose2d(21, 21, kernel_size = (16,16), stride = (8,8), padding = 4)\n",
    "        #pool3,4 conv\n",
    "        self.pool3conv = nn.Conv2d(256, 21, kernel_size = (1,1))\n",
    "        self.pool4conv = nn.Conv2d(512, 21, kernel_size = (1,1), padding = 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu1_1(self.conv1_1(x))\n",
    "        x = self.relu1_2(self.conv1_2(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.relu2_1(self.conv2_1(x))\n",
    "        x = self.relu2_2(self.conv2_2(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.relu3_1(self.conv3_1(x))\n",
    "        x = self.relu3_2(self.conv3_2(x))\n",
    "        x = self.relu3_3(self.conv3_3(x))\n",
    "        x = self.pool3(x)\n",
    "        pool3 = x\n",
    "        \n",
    "        x = self.relu4_1(self.conv4_1(x))\n",
    "        x = self.relu4_2(self.conv4_2(x))\n",
    "        x = self.relu4_3(self.conv4_3(x))\n",
    "        x = self.pool4(x)\n",
    "        pool4 = x\n",
    "        \n",
    "        x = self.relu5_1(self.conv5_1(x))\n",
    "        x = self.relu5_2(self.conv5_2(x))\n",
    "        x = self.relu5_3(self.conv5_3(x))\n",
    "        x = self.pool5(x)\n",
    "        \n",
    "        x = self.drop6(self.relu6(self.conv6(x)))\n",
    "        x = self.drop7(self.relu7(self.conv7(x)))\n",
    "        x = self.score1(x)\n",
    "        \n",
    "        x = self.x2upsamp(x)\n",
    "        \n",
    "        pool4 = self.pool4conv(pool4)\n",
    "\n",
    "        x = x + pool4\n",
    "        x = self.x2upsamp(x)\n",
    "        \n",
    "        pool3 = self.pool3conv(pool3)\n",
    "        \n",
    "        x = x + pool3\n",
    "        x = self.x8upsamp(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b43cf910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [1, 64, 256, 256]           1,792\n",
      "              ReLU-2          [1, 64, 256, 256]               0\n",
      "            Conv2d-3          [1, 64, 256, 256]          36,928\n",
      "              ReLU-4          [1, 64, 256, 256]               0\n",
      "         MaxPool2d-5          [1, 64, 128, 128]               0\n",
      "            Conv2d-6         [1, 128, 128, 128]          73,856\n",
      "              ReLU-7         [1, 128, 128, 128]               0\n",
      "            Conv2d-8         [1, 128, 128, 128]         147,584\n",
      "              ReLU-9         [1, 128, 128, 128]               0\n",
      "        MaxPool2d-10           [1, 128, 64, 64]               0\n",
      "           Conv2d-11           [1, 256, 64, 64]         295,168\n",
      "             ReLU-12           [1, 256, 64, 64]               0\n",
      "           Conv2d-13           [1, 256, 64, 64]         590,080\n",
      "             ReLU-14           [1, 256, 64, 64]               0\n",
      "           Conv2d-15           [1, 256, 64, 64]         590,080\n",
      "             ReLU-16           [1, 256, 64, 64]               0\n",
      "        MaxPool2d-17           [1, 256, 32, 32]               0\n",
      "           Conv2d-18           [1, 512, 32, 32]       1,180,160\n",
      "             ReLU-19           [1, 512, 32, 32]               0\n",
      "           Conv2d-20           [1, 512, 32, 32]       2,359,808\n",
      "             ReLU-21           [1, 512, 32, 32]               0\n",
      "           Conv2d-22           [1, 512, 32, 32]       2,359,808\n",
      "             ReLU-23           [1, 512, 32, 32]               0\n",
      "        MaxPool2d-24           [1, 512, 16, 16]               0\n",
      "           Conv2d-25           [1, 512, 16, 16]       2,359,808\n",
      "             ReLU-26           [1, 512, 16, 16]               0\n",
      "           Conv2d-27           [1, 512, 16, 16]       2,359,808\n",
      "             ReLU-28           [1, 512, 16, 16]               0\n",
      "           Conv2d-29           [1, 512, 16, 16]       2,359,808\n",
      "             ReLU-30           [1, 512, 16, 16]               0\n",
      "        MaxPool2d-31             [1, 512, 8, 8]               0\n",
      "           Conv2d-32            [1, 4096, 8, 8]       2,101,248\n",
      "             ReLU-33            [1, 4096, 8, 8]               0\n",
      "        Dropout2d-34            [1, 4096, 8, 8]               0\n",
      "           Conv2d-35            [1, 4096, 8, 8]      16,781,312\n",
      "             ReLU-36            [1, 4096, 8, 8]               0\n",
      "        Dropout2d-37            [1, 4096, 8, 8]               0\n",
      "           Conv2d-38              [1, 21, 8, 8]          86,037\n",
      "  ConvTranspose2d-39            [1, 21, 16, 16]           7,077\n",
      "           Conv2d-40            [1, 21, 16, 16]          10,773\n",
      "  ConvTranspose2d-41            [1, 21, 32, 32]           7,077\n",
      "           Conv2d-42            [1, 21, 32, 32]           5,397\n",
      "  ConvTranspose2d-43          [1, 21, 256, 256]         112,917\n",
      "================================================================\n",
      "Total params: 33,826,526\n",
      "Trainable params: 33,826,526\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 308.17\n",
      "Params size (MB): 129.04\n",
      "Estimated Total Size (MB): 437.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = FCN_8s()\n",
    "summary_(model.to('cuda'), (3, 256, 256), batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9229d74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_voc_images(train = True):\n",
    "    file = 'VOCdevkit/VOC2012/ImageSets/Segmentation/' + ('train.txt' if train else 'val.txt')\n",
    "    mode = torchvision.io.image.ImageReadMode.RGB\n",
    "    with open(file, 'r') as f:\n",
    "        imgs = f.read().split()\n",
    "    datas, targets = [], []\n",
    "    for i, imgname in enumerate(imgs):\n",
    "        datas.append(torchvision.io.read_image(os.path.join('VOCdevkit/VOC2012/JPEGImages', f'{imgname}.jpg')))\n",
    "        targets.append(torchvision.io.read_image(os.path.join('VOCdevkit/VOC2012/SegmentationClass', f'{imgname}.png'), mode))\n",
    "    return datas, targets\n",
    "\n",
    "Color_Map = [\n",
    "               [0, 0, 0],  # background\n",
    "               [128, 0, 0], # aeroplane\n",
    "               [0, 128, 0], # bicycle\n",
    "               [128, 128, 0], # bird\n",
    "               [0, 0, 128], # boat\n",
    "               [128, 0, 128], # bottle\n",
    "               [0, 128, 128], # bus \n",
    "               [128, 128, 128], # car\n",
    "               [64, 0, 0], # cat\n",
    "               [192, 0, 0], # chair\n",
    "               [64, 128, 0], # cow\n",
    "               [192, 128, 0], # dining table\n",
    "               [64, 0, 128], # dog\n",
    "               [192, 0, 128], # horse\n",
    "               [64, 128, 128], # motorbike\n",
    "               [192, 128, 128], # person\n",
    "               [0, 64, 0], # potted plant\n",
    "               [128, 64, 0], # sheep\n",
    "               [0, 192, 0], # sofa\n",
    "               [128, 192, 0], # train\n",
    "               [0, 64, 128] # tv/monitor\n",
    "]\n",
    "\n",
    "def voccolormap2label():\n",
    "    colormap2label = torch.zeros(256**3, dtype=torch.long)\n",
    "    for i, cm in enumerate(Color_Map):\n",
    "        colormap2label[(cm[0] * 256 + cm[1]) * 256 +cm[2]] = i\n",
    "    return colormap2label\n",
    "\n",
    "def voclabel_indices(colormap, colormap2label):\n",
    "    colormap = colormap.permute(1, 2, 0).numpy().astype('int32')\n",
    "    idx = ((colormap[:,:,0] * 256 + colormap[:,:,1]) * 256 + colormap[:,:,2])\n",
    "    return colormap2label[idx]\n",
    "\n",
    "def vocrand_crop(data, target, h, w):\n",
    "    rect = transforms.RandomCrop.get_params(data, (h,w))\n",
    "    data = transforms.functional.crop(data, *rect)\n",
    "    target = transforms.functional.crop(target, *rect)\n",
    "    return data, target\n",
    "\n",
    "class VOCSegDataset(data.Dataset):\n",
    "    def __init__(self, train, img_size):\n",
    "        self.transform = transforms.Normalize(mean = [0.485,0.456,0.406],\n",
    "                                             std = [0.229,0.224,0.225])\n",
    "        self.img_size = img_size\n",
    "        datas, targets = read_voc_images(train = train)\n",
    "        self.datas = [self.normalize_image(data) for data in self.filter(datas)]\n",
    "        self.targets = self.filter(targets)\n",
    "        self.colormap2label = voccolormap2label()\n",
    "        \n",
    "    def normalize_image(self, img):\n",
    "        return self.transform(img.float())\n",
    "    \n",
    "    def filter(self, imgs):\n",
    "        return [img for img in imgs if(img.shape[1] >= self.img_size[0] and img.shape[2] >= self.img_size[1])]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data, target = vocrand_crop(self.datas[idx], self.targets[idx], *self.img_size)\n",
    "        return (data, voclabel_indices(target, self.colormap2label))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.datas)\n",
    "###\n",
    "\n",
    "img_size = (256, 256)\n",
    "train_data = VOCSegDataset(train = True, img_size = img_size)\n",
    "valid_data = VOCSegDataset(train = False, img_size = img_size)\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "valid_loader = data.DataLoader(valid_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "78b797fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-64-eaf9dd1fead0>:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = F.log_softmax(output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/1444 (0%)\tloss:3.0547]\n",
      "Train Epoch: 1 [200/1444 (14%)\tloss:1.3495]\n",
      "Train Epoch: 1 [400/1444 (28%)\tloss:1.7294]\n",
      "Train Epoch: 1 [600/1444 (42%)\tloss:1.7199]\n",
      "Train Epoch: 1 [800/1444 (55%)\tloss:2.3142]\n",
      "Train Epoch: 1 [1000/1444 (69%)\tloss:2.5331]\n",
      "Train Epoch: 1 [1200/1444 (83%)\tloss:2.0111]\n",
      "Train Epoch: 1 [1400/1444 (97%)\tloss:1.5274]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-eaf9dd1fead0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-64-eaf9dd1fead0>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(device, model, valid_loader)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mcorrect\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'bool' object has no attribute 'sum'"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "criterion = nn.NLLLoss()\n",
    "test_criterion = nn.NLLLoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.0001, weight_decay = 0.0016, momentum = 0.9)\n",
    "\n",
    "def train(device, mode, train_loader, optimizer,epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        inputs = Variable(data)\n",
    "        targets = Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs)\n",
    "        output = F.log_softmax(output)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 200 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)\\tloss:{:.4f}]'\n",
    "                 .format(epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                        100 * batch_idx / len(train_loader),\n",
    "                        loss.item()))\n",
    "            \n",
    "def evaluate(device, model, valid_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in valid_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += test_criterion(output, target).item()\n",
    "            \n",
    "            predicted = torch.max(output.data, 1)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    \n",
    "    test_loss /= len(valid_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(valid_loader.dataset)\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(device, model, train_loader, optimizer, epoch)\n",
    "    test_loss, test_accuracy = evaluate(device, model, valid_loader)\n",
    "    \n",
    "    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38314905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
